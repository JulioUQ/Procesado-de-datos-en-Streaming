# ğŸ“˜ Procesamiento de Datos en Flujo (Streaming)

Este repositorio contiene materiales, ejercicios y ejemplos prÃ¡cticos relacionados con el **procesamiento de datos en flujo** dentro del contexto del Big Data. El objetivo es disponer de un espacio inicial que irÃ¡ ampliÃ¡ndose progresivamente a medida que avance el desarrollo del mÃ³dulo y las actividades asociadas.

## ğŸ§© Planteamiento del MÃ³dulo

El mÃ³dulo aborda el procesamiento de datos en flujo siguiendo una progresiÃ³n conceptual y prÃ¡ctica similar al procesamiento batch estudiado previamente. Para ello:

### IntroducciÃ³n a los datos en flujo

- Concepto de datos en flujo (streaming): origen y tipologÃ­as.
- Diferencias clave con los sistemas de procesamiento en tiempo real.
- RevisiÃ³n de sistemas de captura de datos en flujo y su utilidad en entornos Big Data.
- AnÃ¡lisis de dos sistemas Big Data que trabajan con datos en streaming, con especial atenciÃ³n a sus mecanismos de captura.

### Arquitecturas Big Data para datos en flujo

- Contexto histÃ³rico que motiva el desarrollo de arquitecturas Big Data.
- CaracterÃ­sticas que debe cumplir un sistema Big Data para el anÃ¡lisis de datos en streaming: robustez, extensibilidad, eficiencia.
- Estudio de las arquitecturas Lambda y Kappa.
- RevisiÃ³n de las publicaciones originales que introducen estos modelos.
- Ejemplo prÃ¡ctico de arquitectura Big Data basada en tecnologÃ­as como:

  - **Apache Spark**
  - **Apache Mesos**
  - **Akka**
  - **Apache Cassandra**
  - **Apache Kafka**

### Procesamiento tÃ©cnico y algoritmos

- Propiedades de los datos en streaming que influyen en el diseÃ±o algorÃ­tmico.
- MÃ©todos exactos y heurÃ­sticos para el anÃ¡lisis de datos en flujo.
- TÃ©cnicas matemÃ¡ticas y aproximadas para tratar grandes volÃºmenes en tiempo limitado.

## Objetivos y Competencias del MÃ³dulo

Al finalizar el mÃ³dulo, el alumnado serÃ¡ capaz de:

- Comprender quÃ© son los datos en flujo (streaming).
- Distinguir entre sistemas de procesamiento en streaming y en tiempo real.
- Conocer las tipologÃ­as de datos en flujo.
- Identificar y aplicar mÃ©todos de captura de datos en flujo en entornos Big Data.
- Comprender la evoluciÃ³n histÃ³rica hacia las arquitecturas Big Data.
- Reconocer las caracterÃ­sticas clave de sistemas Big Data para streaming.
- Conocer las arquitecturas Lambda y Kappa y sus implicaciones.
- Entender cÃ³mo implementar arquitecturas Big Data para el procesamiento de datos en flujo.

## ğŸ“ Objetivos de la Actividad

Esta actividad prÃ¡ctica permite al estudiante:

- Conocer los mÃ©todos bÃ¡sicos de captura de flujos de datos en entornos Big Data.
- Entender y practicar con herramientas fundamentales como:

  - **Apache Flume**
    - [Manual de referencia Apache Flume](https://flume.apache.org/documentation.html)
    - [Referencia del conector usado por Apache Flume](https://github.com/cloudera/cdh-twitter-example)
  - **Apache Streaming:**
    - [Manual de referencia Apache Streaming](https://spark.apache.org/docs/latest/streaming-programming-guide.html)

- Adquirir suficiencia en su uso dentro de pipelines de datos en streaming.

## ğŸ“ Estructura del Repositorio

> _(Este apartado se ampliarÃ¡ conforme el repositorio crezca)_

- `/Teoria` â€“ Material teÃ³rico de referencia.
- `/ejercicios` â€“ Actividades guiadas sobre captura y procesamiento de datos en flujo.
- `/ejemplos` â€“ Scripts y configuraciones de ejemplo para Flume, Kafka y arquitecturas Big Data.

## ğŸš§ Estado Actual

Este README ofrece una descripciÃ³n inicial del mÃ³dulo y su propÃ³sito. SerÃ¡ actualizado a medida que avancen las actividades, se aÃ±adan entregables o se integren nuevas tecnologÃ­as.
